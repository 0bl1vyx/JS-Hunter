#!/bin/bash
# --- Colors & Styles ---
# Hacker minimalist theme: Matrix-inspired greens, subtle cyans, clean contrasts.
HACKER_GREEN=$(tput setaf 2) # Main text and success
CYAN=$(tput setaf 6) # Highlights and info
ORANGE=$(tput setaf 3) # Warnings
RED=$(tput setaf 1) # Errors
WHITE=$(tput setaf 7) # Neutral text
DIM=$(tput dim) # Subtle dim for details
BOLD=$(tput bold)
NC=$(tput sgr0) # No Color

# --- UI Functions ---
banner() {
    echo -e "${HACKER_GREEN}${BOLD}"
    echo "      ██╗███████╗██╗  ██╗██╗   ██║███╗   ██║████████╗███████╗██████╗ "
    echo "      ██║██╔════╝██║  ██║██║   ██║████╗  ██║╚══██╔══╝██╔════╝██╔══██╗"
    echo "      ██║███████╗███████║██║   ██║██╔██╗ ██║   ██║   ███████╗██████╔╝"
    echo "██╗  ██║╚════██║██╔══██║██║   ██║██║╚██╗██║   ██║   ██╔════╝██╔══██╗"
    echo "╚██████║███████║██║  ██║╚██████╔╝██║ ╚████║   ██║   ███████╗██║  ██║"
    echo " ╚═════╝╚══════╝╚═╝  ╚═╝ ╚═════╝ ╚═╝  ╚═══╝   ╚═╝   ╚══════╝╚═╝  ╚═╝"
    echo "                                by Crypt Specter V6.1 (No-Filter Edition)"
    echo -e "${NC}"
}
header() {
    echo -e "\n${CYAN}${BOLD}┌─ ${1} ─┐${NC}"
}
stage() {
    echo -e "${HACKER_GREEN}${BOLD}┃ ${WHITE}${1}${NC}"
}
substage() {
    echo -e "${CYAN}┗━▶ ${1}${NC}"
}
tool_result() {
    echo -e "    ├── ${1}${NC}"
}
detail() {
    if [[ "$VERBOSE" == true ]]; then
        echo -e "${DIM}    • ${1}${NC}"
    fi
}
help_menu() {
    header "Command Guide"
    echo -e "${CYAN}Usage:${NC} $0 [options]\n"
    echo -e "${ORANGE}Essential:${NC}"
    echo -e " -dl <file> Domain list input (txt)"
    echo -e "${ORANGE}Optional:${NC}"
    echo -e " -o <file>  JS URLs output"
    echo -e " -s <file>  Secrets output"
    echo -e " -cs <file> Verify secrets and save to file (requires -s)"
    echo -e " -p <file>  Paths output"
    echo -e " -l <file>  Links output"
    echo -e " -lv <1-4>  Discovery level (default: 4)"
    echo -e " -c <num>   Concurrency level (default: 4)"
    echo -e " -v         Verbose output (extra details)"
    echo -e " -h, --help This guide\n"
    echo -e "${HACKER_GREEN}Example:${NC} $0 -dl domains.txt -o js.txt -s secrets.txt -cs verified.txt -p paths.txt -l links.txt -lv 2 -c 8 -v"
    exit 0
}
error() {
    echo -e "\n${RED}${BOLD}✖ Error: ${1}${NC}"
    exit 1
}
warn() {
    echo -e "${ORANGE}${BOLD}⚠ Warning: ${1}${NC}"
}
info() {
    echo -e "${CYAN}ℹ ${1}${NC}"
}
confirm_overwrite() {
    local file="$1"
    if [[ -f "$file" ]]; then
        read -p "${ORANGE}⁉ Overwrite $file? (y/n): ${NC}" confirm
        if [[ "$confirm" != "y" && "$confirm" != "Y" ]]; then
            error "Aborted."
        fi
    fi
}

# Trap for cleanup
trap 'rm -f "$DOMAINS" "$URLS" "$ALL_JS_URLS" "${results[@]}" "$ANALYSIS_RESULTS" "$SECRETS_LIST" 2>/dev/null' EXIT

# --- Argument Parsing ---
DOMAIN_LIST_INPUT=""
JS_URLS_FILE=""
SECRETS_FILE=""
VERIFIED_SECRETS_FILE=""
PATHS_FILE=""
LINKS_FILE=""
LEVEL=4
CONCURRENCY=4
VERBOSE=false
while [[ $# -gt 0 ]]; do
    key="$1"
    case $key in
        -dl|-o|-s|-cs|-p|-l|-lv|-c)
            if [[ $# -lt 2 || "$2" == -* ]]; then
                error "Missing value for $key"
            fi
            value="$2"
            shift 2
            case $key in
                -dl) DOMAIN_LIST_INPUT="$value" ;;
                -o) JS_URLS_FILE="$value" ;;
                -s) SECRETS_FILE="$value" ;;
                -cs) VERIFIED_SECRETS_FILE="$value" ;;
                -p) PATHS_FILE="$value" ;;
                -l) LINKS_FILE="$value" ;;
                -lv) LEVEL="$value" ;;
                -c) CONCURRENCY="$value" ;;
            esac
            ;;
        -v) VERBOSE=true; shift ;;
        -h|--help) help_menu ;;
        *) error "Invalid option: $1" ;;
    esac
done

# --- Validation ---
[[ -z "$DOMAIN_LIST_INPUT" ]] && error "Domain list required (-dl <file>)"
[[ ! -f "$DOMAIN_LIST_INPUT" ]] && error "File '$DOMAIN_LIST_INPUT' not found"
[[ ! "$LEVEL" =~ ^[1-4]$ ]] && error "Level must be 1-4"
[[ ! "$CONCURRENCY" =~ ^[1-9][0-9]*$ ]] && error "Concurrency must be a positive integer"
[[ -n "$VERIFIED_SECRETS_FILE" && -z "$SECRETS_FILE" ]] && error "-cs requires -s"

# --- Dynamic Dependency Check ---
declare -A tools=(
    [1]="subjs"
    [2]="katana"
    [3]="waybackurls"
    [4]="gau"
)
# httpx removed from this list
dependencies=("curl" "grep" "sed" "sort" "wc" "awk" "tr")
for i in $(seq 1 "$LEVEL"); do
    dependencies+=("${tools[$i]}")
done
dependencies=($(echo "${dependencies[@]}" | tr ' ' '\n' | sort -u | tr '\n' ' '))
for dep in "${dependencies[@]}"; do
    command -v "$dep" &> /dev/null || error "Missing: $dep"
done
detail "Dependencies checked: ${dependencies[*]}"

# --- Overwrite Confirmation ---
[[ -n "$JS_URLS_FILE" ]] && confirm_overwrite "$JS_URLS_FILE"
[[ -n "$SECRETS_FILE" ]] && confirm_overwrite "$SECRETS_FILE"
[[ -n "$VERIFIED_SECRETS_FILE" ]] && confirm_overwrite "$VERIFIED_SECRETS_FILE"
[[ -n "$PATHS_FILE" ]] && confirm_overwrite "$PATHS_FILE"
[[ -n "$LINKS_FILE" ]] && confirm_overwrite "$LINKS_FILE"

# --- Main Execution ---
clear
banner
start_time=$(date +%s)
detail "Processing input: $DOMAIN_LIST_INPUT"
DOMAINS=$(mktemp)
sed -E 's|^https?://||' "$DOMAIN_LIST_INPUT" | sort -u > "$DOMAINS"
detail "Domains prepared: $(wc -l < "$DOMAINS") unique"
URLS=$(mktemp)
awk '{print "https://" $0}' "$DOMAINS" > "$URLS"
detail "URLs ready for scanning"
UA="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"
detail "User-Agent set: $UA"

# --- Spinner Frames ---
SPINNER_FRAMES='⠋⠙⠹⠸⠼⠴⠦⠧⠇⠏'

# --- Discovery Phase ---
stage "Phase 1: Discovering JavaScript URLs (Level: $LEVEL)"
declare -A pids
declare -A results
for i in $(seq 1 $LEVEL); do
    tool=${tools[$i]}
    results[$tool]=$(mktemp)
    detail "Launching $tool"
    detail "Temp file: ${results[$tool]}"
    case $tool in
        "subjs")
            subjs -i "$URLS" -ua "$UA" -c "$CONCURRENCY" > "${results[$tool]}" &
            ;;
        "katana")
            cat "$URLS" | xargs -P "$CONCURRENCY" -I {} sh -c "katana -u {} -jc -silent -H 'User-Agent: $UA' | grep -Ei '\.js([?#].*)?\$' >> '${results[$tool]}' || true" &
            ;;
        "waybackurls")
            cat "$DOMAINS" | xargs -P "$CONCURRENCY" -I {} sh -c "waybackurls {} | grep -Ei '\.js([?#].*)?\$' >> '${results[$tool]}' || true" &
            ;;
        "gau")
            cat "$DOMAINS" | xargs -P "$CONCURRENCY" -I {} sh -c "gau {} 2>/dev/null | grep -Ei '\.js([?#].*)?\$' >> '${results[$tool]}' || true" &
            ;;
    esac
    pids[$tool]=$!
    detail "PID: ${pids[$tool]}"
done
# Spinner animation
printf "${CYAN}┗━▶ Discovery in Progress...${NC} "
spinner_i=0
while true; do
    all_done=true
    for pid in "${pids[@]}"; do
        if kill -0 "$pid" 2>/dev/null; then
            all_done=false
        fi
    done
    if $all_done; then break; fi
    spinner_char="${SPINNER_FRAMES:$((spinner_i % ${#SPINNER_FRAMES})):1}"
    printf "\r${CYAN}┗━▶ Discovery in Progress... $spinner_char${NC} "
    spinner_i=$((spinner_i + 1))
    sleep 0.1
done
printf "\r${CYAN}┗━▶ Discovery Complete.        ${NC}\n"
# Check exit codes
for tool in "${!pids[@]}"; do
    wait "${pids[$tool]}"
    exit_code=$?
    if [[ $exit_code -ne 0 ]]; then
        warn "$tool failed (code $exit_code)"
    else
        detail "$tool complete: $(wc -l < "${results[$tool]}") URLs"
    fi
done
for tool in "${!results[@]}"; do
    tool_result "$tool : $(wc -l < "${results[$tool]}") URLs found"
done

# --- Consolidation Phase ---
stage "Phase 2: Consolidating URLs"
ALL_JS_URLS=$(mktemp)
detail "Merging results into: $ALL_JS_URLS"
cat "${results[@]}" | sort -u > "$ALL_JS_URLS"
total_js=$(wc -l < "$ALL_JS_URLS" | tr -d ' ')
substage "Found $total_js unique JS URLs."
[[ $total_js -eq 0 ]] && error "No JS URLs found"

# --- Prepare for Analysis ---
# Skipping live URL check. All found URLs will be analyzed directly.
SCAN_TARGETS="$ALL_JS_URLS"
urls_for_analysis=$total_js
substage "Analyzing all $urls_for_analysis URLs."

if [[ -n "$JS_URLS_FILE" ]]; then
    cp "$ALL_JS_URLS" "$JS_URLS_FILE"
    detail "Exported all unique JS URLs to $JS_URLS_FILE"
fi

# --- Analysis Phase ---
stage "Phase 3: Analysis Phase (Native)"
SECRETS_FOUND=0
VERIFIED_SECRETS_FOUND=0
PATHS_FOUND=0
LINKS_FOUND=0
SECRETS_LIST=""

# This function is exported and run in parallel for each URL.
# It fetches the URL content once and scans for secrets, paths, and links.
process_js_url() {
    local url="$1"
    # Using --connect-timeout to prevent hanging, -L to follow redirects
    local content
    content=$(curl --connect-timeout 5 -s -L -A "$UA" "$url")

    # Exit if content is empty
    if [[ -z "$content" ]]; then
        return
    fi

    # --- Find Secrets ---
    if [[ "$ENABLE_SECRETS" == "true" ]]; then
        declare -A regexes
        regexes[slack_token]="(xox[bapso]-[0-9]{12}-[0-9]{12}-[0-9]{12}-[a-z0-9]{32})"
        regexes[facebook_access_token]="(EAACEdEose0cBA[A-Za-z0-9]+)"
        regexes[github_personal_access_token]="(gh[pousr]_[0-9a-zA-Z]{36})"
        regexes[google_api_key]="(AIza[0-9A-Za-z\\-_]{35})"
        regexes[twilio_auth_token]="(SK[0-9a-fA-F]{32})"
        regexes[aws_access_key_id]="(AKIA[0-9A-Z]{16})"
        regexes[firebase_database_url]="(https?://([a-z0-9-]+\\.firebaseio\\.com|([a-z0-9-]+\\.)?firebasedatabase\\.app)/?)"
        regexes[asana_access_token]="([0-9]{8}:[a-zA-Z0-9]{84})"

        for type in "${!regexes[@]}"; do
            echo "$content" | grep -oP "${regexes[$type]}" | sed "s/^/SECRET::$type::/"
        done
    fi

    # --- Find Paths ---
    if [[ "$ENABLE_PATHS" == "true" ]]; then
        echo "$content" | grep -aEio '(["'"'"'`])(/?([a-zA-Z0-9_./-]+\?)[a-zA-Z0-9_=&.-]*|/?([a-zA-Z0-9_./-]+))(["'"'"'`])' | sed -E 's/^.(.*).$/\1/' | grep '^/' | sed 's/^/PATH::/'
    fi

    # --- Find Links ---
    if [[ "$ENABLE_LINKS" == "true" ]]; then
        echo "$content" | grep -aEio '(["'"'"'`])(https?://[a-zA-Z0-9@_./?=&%:-]+)(["'"'"'`])' | sed -E 's/^.(.*).$/\1/' | sed 's/^/LINK::/'
    fi
}

ANALYSIS_RESULTS=""
analysis_pid=""

if [[ -n "$SECRETS_FILE" || -n "$PATHS_FILE" || -n "$LINKS_FILE" ]]; then
    
    # Set flags for the exported function to avoid checking file paths inside it
    ENABLE_SECRETS="false" && [[ -n "$SECRETS_FILE" ]] && ENABLE_SECRETS="true"
    ENABLE_PATHS="false" && [[ -n "$PATHS_FILE" ]] && ENABLE_PATHS="true"
    ENABLE_LINKS="false" && [[ -n "$LINKS_FILE" ]] && ENABLE_LINKS="true"
    
    export -f process_js_url
    export UA ENABLE_SECRETS ENABLE_PATHS ENABLE_LINKS

    ANALYSIS_RESULTS=$(mktemp)
    detail "Aggregating analysis results into: $ANALYSIS_RESULTS"

    cat "$SCAN_TARGETS" | xargs -P "$CONCURRENCY" -I {} bash -c 'process_js_url "{}"' > "$ANALYSIS_RESULTS" &
    analysis_pid=$!
    
    # Spinner animation
    printf "${CYAN}┗━▶ Analysis in Progress...${NC} "
    spinner_i=0
    while kill -0 "$analysis_pid" 2>/dev/null; do
        spinner_char="${SPINNER_FRAMES:$((spinner_i % ${#SPINNER_FRAMES})):1}"
        printf "\r${CYAN}┗━▶ Analysis in Progress... $spinner_char${NC} "
        spinner_i=$((spinner_i + 1))
        sleep 0.1
    done
    wait "$analysis_pid"
    printf "\r${CYAN}┗━▶ Analysis Complete.        ${NC}\n"

    # Process aggregated results from the temp file
    if [[ "$ENABLE_SECRETS" == "true" ]]; then
        grep '^SECRET::' "$ANALYSIS_RESULTS" | sed -E 's/^SECRET::([^:]+)::(.*)/\1: \2/' | sort -u > "$SECRETS_FILE"
        SECRETS_FOUND=$(wc -l < "$SECRETS_FILE" | tr -d ' ')
        detail "Secrets found: $SECRETS_FOUND"
        if [[ $SECRETS_FOUND -eq 0 ]]; then
            rm "$SECRETS_FILE"
            SECRETS_FILE=""
            detail "Empty secrets file removed"
        fi
    fi

    if [[ "$ENABLE_PATHS" == "true" ]]; then
        grep '^PATH::' "$ANALYSIS_RESULTS" | cut -d':' -f3- | grep -viE '\.(js|css|png|jpg|jpeg|gif|svg|ico|woff2?|ttf|map|eot|otf|xml|json|txt|md)(\?|$)' | sort -u > "$PATHS_FILE"
        PATHS_FOUND=$(wc -l < "$PATHS_FILE" | tr -d ' ')
        detail "Paths found: $PATHS_FOUND"
        if [[ $PATHS_FOUND -eq 0 ]]; then
            rm "$PATHS_FILE"
            PATHS_FILE=""
            detail "Empty paths file removed"
        fi
    fi

    if [[ "$ENABLE_LINKS" == "true" ]]; then
        grep '^LINK::' "$ANALYSIS_RESULTS" | cut -d':' -f3- | grep -viE '\.(js|css|png|jpg|jpeg|gif|svg|ico|woff2?|ttf|map|eot|otf|xml|json|txt|md)(\?|$)' | sort -u > "$LINKS_FILE"
        LINKS_FOUND=$(wc -l < "$LINKS_FILE" | tr -d ' ')
        detail "Links found: $LINKS_FOUND"
        if [[ $LINKS_FOUND -eq 0 ]]; then
            rm "$LINKS_FILE"
            LINKS_FILE=""
            detail "Empty links file removed"
        fi
    fi
fi

# Handle verified if no secrets were found to begin with
if [[ -z "$SECRETS_FILE" && -n "$VERIFIED_SECRETS_FILE" ]]; then
    rm -f "$VERIFIED_SECRETS_FILE" 2>/dev/null
    VERIFIED_SECRETS_FILE=""
    VERIFIED_SECRETS_FOUND=0
    detail "No secrets to verify; cleaned verified file"
fi

# --- Verification Phase ---
if [[ -n "$VERIFIED_SECRETS_FILE" && -n "$SECRETS_FILE" ]]; then
    stage "Phase 3.1: Verifying Secrets"
    > "$VERIFIED_SECRETS_FILE"
    SECRETS_LIST=$(mktemp)
    # Note: Only secrets with a verification method are added to the list
    grep -E '^(slack_token|facebook_access_token|github_personal_access_token|google_api_key|cloudflare_api_token|firebase_database_url|datadog_api_key|browserstack_access_key|asana_access_token):' "$SECRETS_FILE" | while read -r line; do
        type=$(echo "$line" | cut -d: -f1 | tr -d ' ')
        secret=$(echo "$line" | cut -d: -f2- | sed 's/^[ \t]*//;s/[ \t]*$//')
        if [[ -n "$secret" ]]; then
            echo "$type $secret" >> "$SECRETS_LIST"
        fi
    done
    total_secrets=$(wc -l < "$SECRETS_LIST" | tr -d ' ')
    if [[ $total_secrets -gt 0 ]]; then
        detail "Verifying $total_secrets secrets"
        cat "$SECRETS_LIST" | xargs -P "$CONCURRENCY" -n 2 sh -c '
            type=$1; secret=$2
            case "$type" in
                slack_token)
                    cmd="curl -s -X POST \"https://slack.com/api/auth.test\" -H \"Authorization: Bearer $secret\""
                    check="{\"ok\":true"
                    ;;
                facebook_access_token)
                    cmd="curl -s \"https://graph.facebook.com/me?access_token=$secret\""
                    check="\"id\":"
                    ;;
                github_personal_access_token)
                    cmd="curl -s -H \"Authorization: token $secret\" \"https://api.github.com/user\""
                    check="\"login\":"
                    ;;
                google_api_key)
                    cmd="curl -s \"https://www.googleapis.com/discovery/v1/apis?key=$secret\""
                    check="\"kind\":\"DiscoveryDocument"
                    ;;
                cloudflare_api_token)
                    cmd="curl -s -X GET \"https://api.cloudflare.com/client/v4/user/tokens/verify\" -H \"Authorization: Bearer $secret\" -H \"Content-Type: application/json\""
                    check="\"success\":true"
                    ;;
                firebase_database_url)
                    cmd="curl -s \"$secret.json?auth=dev\""
                    check="^{\""
                    ;;
                datadog_api_key)
                    cmd="curl -s -H \"DD-API-KEY: $secret\" \"https://api.datadoghq.com/api/v1/validate\""
                    check="\"valid\":true"
                    ;;
                browserstack_access_key)
                    cmd="curl -s -u \"$secret:unused\" \"https://api.browserstack.com/automate/users.json\""
                    check="\"hashed_id\":"
                    ;;
                asana_access_token)
                    cmd="curl -s -H \"Authorization: Bearer $secret\" \"https://app.asana.com/api/1.0/users/me\""
                    check="\"gid\":"
                    ;;
                *) exit 0 ;;
            esac
            output=$(eval "$cmd")
            if echo "$output" | grep -q "$check"; then
                echo "$type: $secret (verified)"
            fi
        ' sh >> "$VERIFIED_SECRETS_FILE" &
        verification_pid=$!
        # Spinner animation
        printf "${CYAN}┗━▶ Verification in Progress...${NC} "
        spinner_i=0
        while kill -0 "$verification_pid" 2>/dev/null; do
            spinner_char="${SPINNER_FRAMES:$((spinner_i % ${#SPINNER_FRAMES})):1}"
            printf "\r${CYAN}┗━▶ Verification in Progress... $spinner_char${NC} "
            spinner_i=$((spinner_i + 1))
            sleep 0.1
        done
        printf "\r${CYAN}┗━▶ Verification Complete.        ${NC}\n"
        wait "$verification_pid"
        exit_code=$?
        if [[ $exit_code -ne 0 ]]; then
            warn "Verification failed (code $exit_code)"
        fi
    fi
    VERIFIED_SECRETS_FOUND=$(wc -l < "$VERIFIED_SECRETS_FILE" | tr -d ' ')
    detail "Verified secrets: $VERIFIED_SECRETS_FOUND"
    if [[ $VERIFIED_SECRETS_FOUND -eq 0 ]]; then
        rm "$VERIFIED_SECRETS_FILE"
        VERIFIED_SECRETS_FILE=""
        detail "Empty verified file removed"
    fi
fi

# --- Summary ---
end_time=$(date +%s)
total_time=$((end_time - start_time))
stage "Phase 4: Results Summary"
substage "Recon complete. 🎉"
echo -e "    ├── Total JS URLs Found: $total_js 🚀"
echo -e "    ├── URLs for Analysis: $urls_for_analysis 🎯"
[[ -n "$JS_URLS_FILE" ]] && echo -e "    ├── JS File: $JS_URLS_FILE 📄"
if [[ -n "$SECRETS_FILE" ]]; then
    echo -e "    ├── Secrets: $SECRETS_FOUND ⚠️ ($SECRETS_FILE)"
else
    echo -e "    ├── Secrets: 0 (None)"
fi
if [[ -n "$VERIFIED_SECRETS_FILE" ]]; then
    echo -e "    ├── Verified Secrets: $VERIFIED_SECRETS_FOUND 🔒 ($VERIFIED_SECRETS_FILE)"
else
    echo -e "    ├── Verified Secrets: 0 (None)"
fi
if [[ -n "$PATHS_FILE" ]]; then
    echo -e "    ├── Paths: $PATHS_FOUND 🛤️ ($PATHS_FILE)"
else
    echo -e "    ├── Paths: 0 (None)"
fi
if [[ -n "$LINKS_FILE" ]]; then
    echo -e "    ├── Links: $LINKS_FOUND 🔗 ($LINKS_FILE)"
else
    echo -e "    ├── Links: 0 (None)"
fi
echo -e "    └── Time Taken: ${total_time}s ⏱"
